# ğŸ“¸ NguyÃªn LÃ½ Chá»¥p 60 Frames

## ğŸ¯ Táº¡i sao cáº§n 60 frames?

### Sign Language lÃ  **Äá»˜NG TÃC**, khÃ´ng pháº£i áº£nh tÄ©nh

```
âŒ SAI: Chá»¥p 1 áº£nh
âœ… ÄÃšNG: Chá»¥p 60 áº£nh (2 giÃ¢y video @ 30fps)
```

**VÃ­ dá»¥:** Äá»™ng tÃ¡c "HELLO"
```
Frame 1-10:   Tay á»Ÿ dÆ°á»›i
Frame 11-30:  GiÆ¡ tay lÃªn âœ‹
Frame 31-50:  Váº«y tay ğŸ‘‹ğŸ‘‹
Frame 51-60:  Háº¡ tay xuá»‘ng
```

â†’ AI cáº§n xem **quá»¹ Ä‘áº¡o chuyá»ƒn Ä‘á»™ng** qua 60 frames Ä‘á»ƒ nháº­n diá»‡n

---

## ğŸ”„ Quy TrÃ¬nh Chá»¥p

### Step 1: Loop chá»¥p 60 láº§n

```typescript
const frames: string[] = [];
const frameCount = 60;

while (frames.length < frameCount) {
  // Chá»¥p 1 frame
  const photo = await cameraRef.current.takePictureAsync({
    base64: true,      // Tráº£ vá» base64 string
    quality: 0.7,      // 70% quality (cÃ¢n báº±ng size vs cháº¥t lÆ°á»£ng)
    skipProcessing: true // Skip post-processing Ä‘á»ƒ nhanh
  });
  
  // LÆ°u vÃ o array
  frames.push(`data:image/jpeg;base64,${photo.base64}`);
  
  // Delay 30ms Ä‘á»ƒ camera ká»‹p xá»­ lÃ½
  await new Promise(resolve => setTimeout(resolve, 30));
}
```

**Timeline:**
```
0ms    â†’ Frame 1  (base64: ~50KB)
30ms   â†’ Frame 2
60ms   â†’ Frame 3
...
1800ms â†’ Frame 60 âœ…

Total: ~3MB data (60 Ã— 50KB)
```

### Step 2: Gá»­i lÃªn backend

```typescript
fetch("/api/process-video", {
  method: "POST",
  body: JSON.stringify({
    frames: frames,        // Array of 60 base64 strings
    lessonPath: "/Family_video2/HELLO.mp4",
    modelId: 1
  })
});
```

### Step 3: Backend xá»­ lÃ½

```python
# Backend: app/api/video.py

user_landmarks = []

# Loop qua 60 frames
for frame_data in frames[:60]:
    # 1. Decode base64 â†’ numpy array
    img_data = base64.b64decode(frame_data.split(',')[1])
    frame = cv2.imdecode(np.frombuffer(img_data, np.uint8))
    
    # 2. Extract landmarks tá»« frame (MediaPipe)
    landmarks = landmark_service.get_frame_landmarks(frame)
    #    â†’ 21 keypoints cho má»—i tay [x, y, z]
    #    â†’ VÃ­ dá»¥: [[0.5, 0.3, 0.1], [0.52, 0.31, 0.11], ...]
    
    user_landmarks.append(landmarks)

# user_landmarks giá» lÃ  array of 60 landmark arrays
# Shape: (60 frames, 21 keypoints, 3 coordinates) = (60, 21, 3)

# 3. LSTM Model xá»­ lÃ½ chuá»—i
user_embedding = model_service.extract_embedding(user_landmarks)
#    â†’ Vector 128D Ä‘áº¡i diá»‡n cho toÃ n bá»™ Ä‘á»™ng tÃ¡c

# 4. So sÃ¡nh vá»›i reference
reference_embedding = np.load("HELLO_embedding.npy")
similarity = cosine_similarity(user_embedding, reference_embedding)
#    â†’ 0.85 (85% giá»‘ng)

# 5. Tráº£ vá» káº¿t quáº£
if similarity > 0.7:
    return "Match!"
else:
    return "No match"
```

---

## ğŸ§  Táº¡i sao AI cáº§n chuá»—i frames?

### LSTM (Long Short-Term Memory) Neural Network

```
Input:  60 frames Ã— 21 keypoints Ã— 3 coords = (60, 21, 3)
        â†“
    [LSTM Layer]  â† Há»c pattern theo thá»i gian
        â†“
    [Dense Layer]
        â†“
Output: 128D embedding vector
```

**LSTM cÃ³ "bá»™ nhá»›":**
- Nhá»› vá»‹ trÃ­ tay á»Ÿ frame trÆ°á»›c
- So sÃ¡nh vá»›i vá»‹ trÃ­ hiá»‡n táº¡i
- Nháº­n biáº¿t **hÆ°á»›ng chuyá»ƒn Ä‘á»™ng**
- Nháº­n biáº¿t **tá»‘c Ä‘á»™ chuyá»ƒn Ä‘á»™ng**

**VÃ­ dá»¥:**
```
HELLO:  Tay lÃªn nhanh â†’ váº«y â†’ xuá»‘ng cháº­m
BYE:    Tay lÃªn cháº­m â†’ váº«y â†’ xuá»‘ng nhanh

â†’ CÃ¹ng "váº«y tay" nhÆ°ng khÃ¡c nhau vá» pattern!
```

---

## âš ï¸ Váº¥n Äá» "Camera Unmounted"

### NguyÃªn nhÃ¢n:

```typescript
// Timeline:
[0s]   Báº¯t Ä‘áº§u chá»¥p 60 frames
[1s]   Äang chá»¥p frame 30/60...
[1.5s] Match! â†’ Countdown 3s...
[2s]   Äang chá»¥p frame 50/60...
[2.5s] ğŸ”¥ Component re-render â†’ Camera unmount!
       âŒ ERROR: Camera unmounted during taking photo
```

**Khi nÃ o xáº£y ra:**
1. Component re-render (props/state thay Ä‘á»•i)
2. Navigation (chuyá»ƒn bÃ i)
3. User táº¯t camera giá»¯a chá»«ng

### Giáº£i phÃ¡p: `isMountedRef`

```typescript
const isMountedRef = useRef(true);

useEffect(() => {
  isMountedRef.current = true;
  return () => {
    isMountedRef.current = false; // Cleanup khi unmount
  };
}, []);

// Trong loop chá»¥p:
while (frames.length < frameCount) {
  // Kiá»ƒm tra component váº«n mounted
  if (!isMountedRef.current) {
    console.log("Component unmounted, stop capture");
    break; // Dá»«ng ngay
  }
  
  try {
    const photo = await takePictureAsync(...);
    frames.push(...);
  } catch (error) {
    if (error.message.includes('unmounted')) {
      break; // Dá»«ng khi camera unmount
    }
  }
}
```

**Táº¡i sao dÃ¹ng `useRef` thay vÃ¬ `useState`?**
- `useRef` khÃ´ng trigger re-render
- GiÃ¡ trá»‹ persist qua cÃ¡c render
- Access Ä‘Æ°á»£c trong async function

---

## ğŸ“Š Performance

### Thá»i gian xá»­ lÃ½:

```
ğŸ“¸ Chá»¥p 60 frames:     ~2-3 giÃ¢y
â³ Encode base64:      ~0.5 giÃ¢y
ğŸ“¤ Upload ~3MB:        ~1-2 giÃ¢y (WiFi)
ğŸ§  Backend xá»­ lÃ½:      ~2-3 giÃ¢y
ğŸ“¥ Nháº­n káº¿t quáº£:       ~0.5 giÃ¢y
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â±ï¸  Tá»”NG:              ~6-11 giÃ¢y
```

### Tá»‘i Æ°u hÃ³a:

**ÄÃ£ lÃ m:**
- âœ… Quality 0.7 (thay vÃ¬ 1.0)
- âœ… skipProcessing: true
- âœ… Delay 30ms (cÃ¢n báº±ng tá»‘c Ä‘á»™ vs á»•n Ä‘á»‹nh)
- âœ… Kiá»ƒm tra mounted Ä‘á»ƒ trÃ¡nh crash

**CÃ³ thá»ƒ lÃ m thÃªm:**
- ğŸ”„ Giáº£m xuá»‘ng 30 frames (1 giÃ¢y)
- ğŸ”„ WebSocket streaming (real-time)
- ğŸ”„ On-device MediaPipe (chá»‰ gá»­i landmarks, nháº¹ hÆ¡n)
- ğŸ”„ Video compression trÆ°á»›c khi gá»­i

---

## ğŸ” Debug & Monitoring

### Console logs há»¯u Ã­ch:

```typescript
console.log("Starting capture 60 frames...");
// Báº¯t Ä‘áº§u chá»¥p

console.log(`Äang chá»¥p ${frames.length}/${frameCount}`);
// Tiáº¿n trÃ¬nh: 10/60, 20/60, ...

console.log(`Total frames captured: ${frames.length}`);
// Káº¿t quáº£: 60/60 hoáº·c 45/60 (thiáº¿u)

console.log("Component unmounted, stopping capture");
// Camera bá»‹ unmount giá»¯a chá»«ng

console.log("Stopping capture due to unmount");
// Dá»«ng vÃ¬ component unmount
```

### Kiá»ƒm tra frames:

```typescript
// Frame thá»© nháº¥t:
console.log(frames[0].substring(0, 50));
// "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQ..."

// KÃ­ch thÆ°á»›c:
console.log(`Frame size: ${frames[0].length} chars`);
// ~66,000 chars = ~50KB

// Tá»•ng size:
const totalSize = frames.reduce((sum, f) => sum + f.length, 0);
console.log(`Total: ${(totalSize / 1024 / 1024).toFixed(2)}MB`);
// ~3.0MB
```

---

## ğŸ’¡ Best Practices

### 1. **Äá»£i camera á»•n Ä‘á»‹nh**
```typescript
// Äá»£i 3 giÃ¢y sau khi báº­t camera
setTimeout(() => {
  sendFramesToAPI(); // Chá»¥p láº§n Ä‘áº§u
}, 3000);
```

### 2. **Interval Ä‘á»§ dÃ i**
```typescript
// Má»—i 6 giÃ¢y (Ä‘á»§ thá»i gian chá»¥p 60 frames)
setInterval(() => {
  if (!isProcessing) {
    sendFramesToAPI();
  }
}, 6000);
```

### 3. **Cleanup khi unmount**
```typescript
useEffect(() => {
  return () => {
    isMountedRef.current = false;
    // CÃ¡c async operation sáº½ tá»± dá»«ng
  };
}, []);
```

### 4. **KhÃ´ng spam error log**
```typescript
if (consecutiveErrors <= 2) {
  console.warn(`Capture error (${consecutiveErrors}/5)`);
}
// Chá»‰ log 2 lá»—i Ä‘áº§u, khÃ´ng spam console
```

---

## ğŸ“ Summary

| Aspect | Detail |
|--------|--------|
| **Sá»‘ frames** | 60 áº£nh |
| **Thá»i gian** | 2 giÃ¢y @ 30fps |
| **KÃ­ch thÆ°á»›c** | ~3MB total |
| **Delay** | 30ms giá»¯a cÃ¡c frame |
| **Quality** | 0.7 (70%) |
| **Backend** | MediaPipe + LSTM |
| **Output** | 128D embedding vector |
| **Similarity** | Cosine similarity (0-1) |
| **Threshold** | 0.7 (70%) Ä‘á»ƒ Match |

**Káº¿t luáº­n:** 60 frames lÃ  cáº§n thiáº¿t Ä‘á»ƒ AI nháº­n diá»‡n chÃ­nh xÃ¡c Ä‘á»™ng tÃ¡c sign language! ğŸ¯

