import React, { useRef, useEffect, useState, useMemo } from "react";
import { View, Text, StyleSheet, TouchableOpacity, Alert, Dimensions, Platform, ScrollView } from "react-native";
import { VideoView, useVideoPlayer } from "expo-video";
import { CameraView, CameraType, useCameraPermissions } from "expo-camera";
import AsyncStorage from "@react-native-async-storage/async-storage";
import { API_CONFIG, getApiUrl, getVideoUrl } from "../constants/config";

// Dynamic requires (avoid hard type deps)
let getThumbnailAsync: any;
try { getThumbnailAsync = require("expo-video-thumbnails").getThumbnailAsync; } catch {}
const FileSystemLegacy: any = (() => {
  try {
    return require("expo-file-system/legacy");
  } catch {
    return null;
  }
})();
const ExpoFileSystem: any = (() => {
  try {
    return require("expo-file-system");
  } catch {
    return null;
  }
})();

const readFileAsBase64 = async (uri: string): Promise<string | null> => {
  if (FileSystemLegacy?.readAsStringAsync) {
    return FileSystemLegacy.readAsStringAsync(uri, { encoding: 'base64' });
  }
  if (ExpoFileSystem?.readAsStringAsync) {
    const encoding = ExpoFileSystem.EncodingType?.Base64 ?? 'base64';
    return ExpoFileSystem.readAsStringAsync(uri, { encoding });
  }
  return null;
};

const { width: SCREEN_WIDTH, height: SCREEN_HEIGHT } = Dimensions.get('window');
const isTablet = SCREEN_WIDTH >= 768;
const isWeb = Platform.OS === 'web';
const isSmallScreen = SCREEN_WIDTH < 600;

interface LessonInfo {
  modelId: number;
  chapterName: string;
  fullChapterName: string;
  lesson: number;
  totalLessonsInChapter: number;
  totalChapters: number;
}

interface LessonProps {
  lessonPath: string;
  lessonName: string;
  apiLessonPath: string;
  lessonInfo: LessonInfo;
  onNextLesson: (currentChapter: string, nextLessonIndex: number) => void;
}

export default function Lesson({
  lessonPath,
  lessonName,
  apiLessonPath,
  lessonInfo,
  onNextLesson,
}: LessonProps) {
  const cameraRef = useRef<CameraView>(null);
  const [permission, requestPermission] = useCameraPermissions();
  const [cameraEnabled, setCameraEnabled] = useState(false);
  const [status, setStatus] = useState("H√£y l√†m h√†nh ƒë·ªông");
  const [countdown, setCountdown] = useState(3);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [facing, setFacing] = useState<CameraType>("front");
  const isMountedRef = useRef(true); // Track component mounted state
  const isCapturingRef = useRef(false); // Track if already capturing
  const statusResetTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null); // track delayed status reset

  const lessonTitle = `${lessonInfo.chapterName}: ${lessonName}`;

  // T·ªëi ∆∞u t·ªëc ƒë·ªô ch·ª•p kh√°c nhau gi·ªØa iPad v√† ƒëi·ªán tho·∫°i
  const CAPTURE_QUALITY = isTablet ? 0.6 : 0.35; // gi·∫£m ch·∫•t l∆∞·ª£ng tr√™n ƒëi·ªán tho·∫°i ƒë·ªÉ ch·ª•p nhanh h∆°n
  const FRAME_DELAY_MS = isTablet ? 20 : 40; // gi√£n nh·ªãp tr√™n ƒëi·ªán tho·∫°i ƒë·ªÉ camera k·ªãp x·ª≠ l√Ω

  // Track component mount/unmount per lesson
  useEffect(() => {
    console.log("Lesson component mounted:", lessonName);
    isMountedRef.current = true;
    isCapturingRef.current = false; // Reset capture flag
    
    return () => {
      console.log("Lesson component unmounting:", lessonName);
      isMountedRef.current = false;
      isCapturingRef.current = false;
      if (statusResetTimeoutRef.current) {
        clearTimeout(statusResetTimeoutRef.current);
        statusResetTimeoutRef.current = null;
      }
      // Stop any ongoing capture
      setIsProcessing(false);
      setIsRecording(false);
    };
  }, [lessonPath]); // Re-mount khi ƒë·ªïi b√†i

  // Request camera permission
  useEffect(() => {
    if (!permission?.granted && cameraEnabled) {
      requestPermission();
    }
  }, [cameraEnabled]);

  // G·ª≠i khung h√¨nh ƒë·∫øn API
  const sendFramesToAPI = async () => {
    // Ki·ªÉm tra component v√† camera c√≤n mounted kh√¥ng
    if (!isMountedRef.current || !cameraRef.current || !apiLessonPath || !cameraEnabled) {
      console.log("Component/Camera not mounted or disabled");
      return;
    }

    // CH·∫∂N N·∫æU ƒêANG CH·ª§P R·ªíI
    if (isCapturingRef.current) {
      console.log("Already capturing, skipping...");
      return;
    }

    isCapturingRef.current = true; // ƒê√°nh d·∫•u ƒëang ch·ª•p
    setIsProcessing(true);
    setIsRecording(true);
    // H·ªßy m·ªçi h·∫πn gi·ªù reset tr·∫°ng th√°i tr∆∞·ªõc ƒë√≥ ƒë·ªÉ tr√°nh ƒë√® status m·ªõi
    if (statusResetTimeoutRef.current) {
      clearTimeout(statusResetTimeoutRef.current);
      statusResetTimeoutRef.current = null;
    }

    try {
      const frames: string[] = [];
      const frameCount = 60;
      let consecutiveErrors = 0;
      const maxConsecutiveErrors = 5;
      
      // Th·ªùi gian d·ª± ki·∫øn: 60 frames √ó 30ms = 1800ms ‚âà 2 gi√¢y
      const estimatedTime = 2000; // ms
      const startTime = Date.now();
      
      console.log("Starting capture 60 frames...");
      
      // ƒê·∫øm ng∆∞·ª£c t·ª´ 3
      for (let i = 3; i > 0; i--) {
        if (isMountedRef.current) {
          setStatus(`${i}...`);
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
      }
      
      if (isMountedRef.current) {
        setStatus("ƒêang quay... üì∏");
        try { (player as any)?.play?.(); } catch {}
      }
      
      let usedVideoPipeline = false;

      // Prefer: quay video 2s v√† tr√≠ch 60 frame tr√™n ƒëi·ªán tho·∫°i (nhanh h∆°n)
      if (!isTablet && (cameraRef.current as any)?.recordAsync && getThumbnailAsync) {
        try {
          const recPromise = (cameraRef.current as any).recordAsync?.({
            maxDuration: Math.ceil(estimatedTime / 1000),
            quality: '480p',
          });
          setTimeout(() => {
            try { (cameraRef.current as any)?.stopRecording?.(); } catch {}
          }, estimatedTime + 200);
          const videoObj = await recPromise;
          const videoUri = videoObj?.uri ?? '';

          if (videoUri) {
            const step = estimatedTime / frameCount;
            for (let i = 0; i < frameCount; i++) {
              const t = Math.min(estimatedTime - 1, Math.floor(i * step));
              try {
                const thumb = await getThumbnailAsync(videoUri, { time: t, quality: 0.6 });
                if (thumb?.uri) {
                  const b64 = await readFileAsBase64(thumb.uri);
                  if (b64) {
                    frames.push(`data:image/jpeg;base64,${b64}`);
                  }
                }
              } catch {}
            }
            usedVideoPipeline = frames.length >= 30;
          }
        } catch {
          // fallback
        }
      }

      // Fallback: ch·ª•p ·∫£nh li√™n ti·∫øp nh∆∞ c≈©
      if (!usedVideoPipeline) {
        while (frames.length < frameCount && consecutiveErrors < maxConsecutiveErrors) {
          if (!isMountedRef.current || !cameraRef.current || !cameraEnabled) {
            console.log("Component/Camera unmounted during capture, stopping...");
            break;
          }
          try {
            const photo = await cameraRef.current.takePictureAsync({
              base64: true,
              quality: CAPTURE_QUALITY,
              skipProcessing: true,
              imageType: 'jpg',
            });
            if (photo?.base64) {
              frames.push(`data:image/jpeg;base64,${photo.base64}`);
              consecutiveErrors = 0;
              const elapsed = Date.now() - startTime;
              const estimatedRemaining = Math.ceil((estimatedTime - elapsed) / 1000);
              if (frames.length % 15 === 0 && isMountedRef.current && estimatedRemaining > 0) {
                setStatus(`ƒêang quay... ${estimatedRemaining}s`);
              }
            }
            await new Promise(resolve => setTimeout(resolve, FRAME_DELAY_MS));
          } catch (error: any) {
            if (!isMountedRef.current || error?.message?.includes('unmounted')) {
              console.log("Stopping capture due to unmount");
              break;
            }
            consecutiveErrors++;
            if (consecutiveErrors <= 2) console.warn(`Capture error (${consecutiveErrors}/${maxConsecutiveErrors})`);
            await new Promise(resolve => setTimeout(resolve, 100));
          }
        }
      }
      
      setIsRecording(false);
      isCapturingRef.current = false; // Reset flag

      // Ki·ªÉm tra component v·∫´n mounted
      if (!isMountedRef.current) {
        console.log("Component unmounted, aborting send");
        return;
      }

      console.log(`Total frames captured: ${frames.length}/${frameCount}`);
      
      // CH·ªà G·ª¨I KHI ƒê·ª¶ 60 FRAMES
      if (frames.length < 60) {
        if (isMountedRef.current) {
          setStatus(`Ch·ª•p l·∫°i (${frames.length}/60)`);
          setIsProcessing(false);
          // T·ª± ƒë·ªông reset sau 2 gi√¢y
          statusResetTimeoutRef.current = setTimeout(() => {
            if (isMountedRef.current) {
              setStatus("H√£y l√†m h√†nh ƒë·ªông");
            }
          }, 2000);
          // clear ref sau khi ch·∫°y
          statusResetTimeoutRef.current && setTimeout(() => (statusResetTimeoutRef.current = null), 0);
        }
        return;
      }
      
      if (isMountedRef.current) {
        setStatus("ƒêang g·ª≠i...");
      }

      const modelId = lessonInfo.modelId;
      if (!modelId) {
        console.error("Missing modelId in lessonInfo:", lessonInfo);
        throw new Error("Missing modelId");
      }

      console.log("Sending frames with modelId:", modelId, "lessonPath:", apiLessonPath);
      
      const token = await AsyncStorage.getItem('token');
      if (!token) {
        console.log("No authentication token found");
      }
      
      const processVideoUrl = getApiUrl(API_CONFIG.ENDPOINTS.PROCESS_VIDEO);
      console.log("Sending to:", processVideoUrl);
      
      const response = await fetch(processVideoUrl, {
        method: "POST",
        headers: { 
          "Content-Type": "application/json",
          "Authorization": `Bearer ${token}`
        },
        body: JSON.stringify({
          frames,
          lessonPath: apiLessonPath,
          modelId: parseInt(String(modelId))
        })
      });

      if (!response.ok) {
        const errorData = await response.json();
        console.error("API Error:", errorData);
        setStatus("L·ªói x·ª≠ l√Ω video");
        throw new Error(`HTTP error! Status: ${response.status}`);
      }

      const result = await response.json();
      console.log("API Response:", result);
      
      const match = result.status === "Match!" || result.status === "match" || result.match === true;

      if (isMountedRef.current) {
        setStatus(match ? "Kh·ªõp!" : "Kh√¥ng kh·ªõp");
      }
      setIsProcessing(false);

      if (match) {
        console.log("‚úÖ Match successful! Moving to next lesson...");
        // T·∫Øt camera khi kh·ªõp
        setCameraEnabled(false);
        
        // B·∫Øt ƒë·∫ßu ƒë·∫øm ng∆∞·ª£c chuy·ªÉn b√†i
        let time = 3;
        if (isMountedRef.current) {
          setCountdown(time);
        }
        const countdownInterval = setInterval(() => {
          time -= 1;
          if (isMountedRef.current) {
            setCountdown(time);
          }
          if (time <= 0) {
            clearInterval(countdownInterval);
            if (isMountedRef.current) {
              goToNextLesson();
              setStatus("H√£y l√†m h√†nh ƒë·ªông");
              setCountdown(3);
            }
          }
        }, 1000);
      } else {
        console.log("‚ùå No match. Try again!");
        // Kh√¥ng kh·ªõp th√¨ gi·ªØ nguy√™n, ƒë·ªÉ user th·ª≠ l·∫°i
        if (isMountedRef.current) {
          // Clear h·∫πn gi·ªù c≈© n·∫øu c√≥
          if (statusResetTimeoutRef.current) {
            clearTimeout(statusResetTimeoutRef.current);
            statusResetTimeoutRef.current = null;
          }
          statusResetTimeoutRef.current = setTimeout(() => {
            if (isMountedRef.current) {
              setStatus("H√£y l√†m h√†nh ƒë·ªông");
            }
          }, 2000);
          // clear ref sau khi ch·∫°y
          statusResetTimeoutRef.current && setTimeout(() => (statusResetTimeoutRef.current = null), 0);
        }
      }
    } catch (error) {
      console.error("L·ªói g·ª≠i khung h√¨nh ƒë·∫øn API:", error);
      setStatus("L·ªói g·ª≠i khung h√¨nh");
      setIsProcessing(false);
      isCapturingRef.current = false; // Reset flag on error
    }
  };

  // Chuy·ªÉn sang b√†i ti·∫øp theo
  const goToNextLesson = () => {
    const { fullChapterName, lesson, modelId } = lessonInfo;
    console.log("Current lesson info:", lessonInfo);
    
    if (!fullChapterName || !modelId) {
      console.error("Invalid chapter info:", { fullChapterName, modelId });
      setStatus("L·ªói chuy·ªÉn b√†i");
      return;
    }

    if (onNextLesson) {
      console.log("Chuy·ªÉn sang b√†i ti·∫øp theo - Chapter:", fullChapterName, "Next Lesson:", lesson + 1);
      onNextLesson(fullChapterName, lesson + 1);
    } else {
      console.error("Missing onNextLesson callback");
      setStatus("L·ªói chuy·ªÉn b√†i");
    }
  };

  // G·ª≠i ƒë·ªãnh k·ª≥
  useEffect(() => {
    let interval: ReturnType<typeof setInterval> | null = null;
    let startDelay: ReturnType<typeof setTimeout> | null = null;
    
    if (cameraEnabled && apiLessonPath && !isProcessing && isMountedRef.current) {
      console.log("Setting up capture timer for lesson:", lessonName);
      
      // ƒê·ª£i 3 gi√¢y sau khi b·∫≠t camera, sau ƒë√≥ ch·ª•p ngay l·∫ßn ƒë·∫ßu
      startDelay = setTimeout(() => {
        if (isMountedRef.current && cameraEnabled && !isCapturingRef.current) {
          console.log("First capture triggered");
          sendFramesToAPI();
        }
      }, 3000);
      
      // Sau ƒë√≥ ch·ª•p m·ªói 10 gi√¢y (ƒë·ªß th·ªùi gian: 3s countdown + 2s capture + 5s buffer)
      interval = setInterval(() => {
        if (isMountedRef.current && cameraEnabled && !isCapturingRef.current) {
          console.log("Interval capture triggered");
          sendFramesToAPI();
        }
      }, 10000); // 10 gi√¢y
    }
    
    return () => {
      console.log("Cleaning up timers for lesson:", lessonName);
      if (startDelay) clearTimeout(startDelay);
      if (interval) clearInterval(interval);
    };
  }, [cameraEnabled, apiLessonPath, lessonPath]); // Th√™m lessonPath ƒë·ªÉ reset khi ƒë·ªïi b√†i

  const handleToggleCamera = async () => {
    if (!cameraEnabled && !permission?.granted) {
      const result = await requestPermission();
      if (!result.granted) {
        Alert.alert("Quy·ªÅn camera", "C·∫ßn quy·ªÅn truy c·∫≠p camera ƒë·ªÉ th·ª±c h√†nh");
        return;
      }
    }
    
    // N·∫øu ƒëang ch·ª•p, d·ª´ng l·∫°i tr∆∞·ªõc
    if (isProcessing || isRecording) {
      setIsProcessing(false);
      setIsRecording(false);
      // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ process d·ª´ng ho√†n to√†n
      await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    setCameraEnabled((prev) => !prev);
    setStatus("H√£y l√†m h√†nh ƒë·ªông");
  };

  // T·∫°o ƒë∆∞·ªùng d·∫´n video t·ª´ public folder - memoize ƒë·ªÉ tr√°nh re-render
  const videoSource = useMemo(() => {
    const url = getVideoUrl(lessonPath);
    console.log("Video source:", url);
    return url;
  }, [lessonPath]);

  // Memoize player ƒë·ªÉ tr√°nh t·∫°o l·∫°i m·ªói render
  const player = useVideoPlayer(videoSource, (player: any) => {
    player.loop = true;
    player.muted = true; // tr√°nh xung ƒë·ªôt audio khi camera ghi video
    player.play();
  });

  return (
    <View style={styles.container}>
      {/* Ti√™u ƒë·ªÅ b√†i h·ªçc */}
      <Text style={styles.mainTitle}>{lessonTitle}</Text>
      
      {/* Layout ngang cho iPad, d·ªçc cho mobile */}
      <View style={styles.contentRow}>
        {/* Video m·∫´u */}
        <View style={styles.videoSection}>
        <Text style={styles.sectionTitle}>üì∫ Video M·∫´u</Text>
          <VideoView
            player={player}
            style={styles.video}
            nativeControls={false}
            allowsPictureInPicture={false}
          />
          
        </View>

        {/* Camera th·ª±c h√†nh */}
        <View style={styles.cameraSection}>
          <Text style={styles.sectionTitle}>üé• Th·ª±c H√†nh</Text>
          <View style={styles.cameraContainer}>
            {cameraEnabled && permission?.granted ? (
              <CameraView
                ref={cameraRef}
                style={styles.camera}
                facing={facing}
                mode="video"
                videoQuality="480p"
              />
            ) : (
              <View style={styles.cameraPlaceholder}>
                <Text style={styles.placeholderIcon}>üì∑</Text>
                <Text style={styles.placeholderText}>
                  {permission?.granted ? "Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ b·∫≠t camera" : "C·∫ßn quy·ªÅn truy c·∫≠p camera"}
                </Text>
              </View>
            )}
          </View>
          
          {/* Tr·∫°ng th√°i */}
          <View style={styles.statusContainer}>
            <Text
              style={[
                styles.statusText,
                status === "Kh·ªõp!" && styles.statusSuccess,
                status === "Kh√¥ng kh·ªõp" && styles.statusError,
                (status === "ƒêang x·ª≠ l√Ω..." || status === "ƒêang ch·ª•p...") && styles.statusProcessing,
              ]}
            >
              {status === "Kh·ªõp!" && "‚úÖ "}
              {status === "Kh√¥ng kh·ªõp" && "‚ùå "}
              {status === "ƒêang ch·ª•p..." && "üì∏ "}
              {status === "ƒêang x·ª≠ l√Ω..." && "‚è≥ "}
              {status}
            </Text>

            {/* ƒê·∫øm ng∆∞·ª£c chuy·ªÉn b√†i */}
            {status === "Kh·ªõp!" && countdown > 0 && (
              <Text style={styles.countdownText}>
                Chuy·ªÉn b√†i trong {countdown}s...
              </Text>
            )}
          </View>
        </View>
      </View>

      {/* N√∫t ƒëi·ªÅu khi·ªÉn FLOAT g√≥c d∆∞·ªõi ph·∫£i */}
      {!cameraEnabled ? (
        <TouchableOpacity
          style={styles.floatButton}
          onPress={handleToggleCamera}
          activeOpacity={0.7}
        >
          <Text style={styles.floatButtonText}>‚ñ∂Ô∏è</Text>
        </TouchableOpacity>
      ) : (
        <TouchableOpacity
          style={[styles.floatButton, styles.floatButtonActive]}
          onPress={handleToggleCamera}
          activeOpacity={0.7}
        >
          <Text style={styles.floatButtonText}>‚èπ</Text>
        </TouchableOpacity>
      )}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f9fafb',
    padding: isSmallScreen ? 8 : isTablet ? 8 : 12,
  },
  mainTitle: {
    fontSize: isSmallScreen ? 18 : isTablet ? 20 : 24,
    fontWeight: 'bold',
    marginBottom: isSmallScreen ? 8 : isTablet ? 6 : 12,
    color: '#1f2937',
    textAlign: 'center',
  },
  contentRow: {
    flex: 1,
    flexDirection: isTablet ? 'row' : 'column',
    gap: isTablet ? 12 : 0,
  },
  videoSection: {
    flex: isTablet ? 1 : 0,
    marginTop: isSmallScreen ? 8 : isTablet ? 12 : 0,
    marginBottom: isSmallScreen ? 8 : isTablet ? 0 : 12,
    backgroundColor: '#ffffff',
    borderRadius: 8,
    padding: isSmallScreen ? 8 : isTablet ? 8 : 12,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  
  cameraSection: {
    flex: isTablet ? 1 : 1,
    backgroundColor: '#ffffff',
    borderRadius: 8,
    padding: isSmallScreen ? 8 : isTablet ? 8 : 12,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  sectionTitle: {
    fontSize: isSmallScreen ? 14 : 16,
    fontWeight: '700',
    marginBottom: 8,
    color: '#374151',
  },
  video: {
    width: '100%',
    height: isSmallScreen ? 250 : isTablet ? SCREEN_HEIGHT * 0.7 : 220,
    backgroundColor: '#000',
    borderRadius: 6,
  },
  cameraContainer: {
    borderRadius: 6,
    overflow: 'hidden',
    marginBottom: 6,
    flex: 1,
  },
  camera: {
    width: '100%',
    height: isSmallScreen ? 300 : isTablet ? '100%' : 340,
  },
  cameraPlaceholder: {
    width: '100%',
    height: isSmallScreen ? 300 : isTablet ? '100%' : 340,
    backgroundColor: '#e5e7eb',
    borderRadius: 6,
    justifyContent: 'center',
    alignItems: 'center',
    gap: 8,
  },
  placeholderIcon: {
    fontSize: 40,
  },
  placeholderText: {
    fontSize: 14,
    color: '#6b7280',
    textAlign: 'center',
    paddingHorizontal: 16,
  },
  statusContainer: {
    alignItems: 'center',
    paddingVertical: 8,
    backgroundColor: '#f3f4f6',
    borderRadius: 6,
  },
  statusText: {
    fontSize: isSmallScreen ? 14 : 16,
    fontWeight: '700',
    color: '#3b82f6',
  },
  statusSuccess: {
    color: '#16a34a',
  },
  statusError: {
    color: '#dc2626',
  },
  statusProcessing: {
    color: '#f59e0b',
  },
  countdownText: {
    fontSize: 12,
    fontWeight: '500',
    marginTop: 4,
    color: '#6b7280',
  },
  // N√∫t FLOAT g√≥c d∆∞·ªõi ph·∫£i
  floatButton: {
    position: 'absolute',
    bottom: isSmallScreen ? 20 : 30,
    right: isSmallScreen ? 20 : 30,
    width: isSmallScreen ? 60 : 70,
    height: isSmallScreen ? 60 : 70,
    borderRadius: isSmallScreen ? 30 : 35,
    backgroundColor: '#10b981',
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 6,
    elevation: 8,
    zIndex: 999,
  },
  floatButtonActive: {
    backgroundColor: '#dc2626',
  },
  floatButtonText: {
    fontSize: isSmallScreen ? 28 : 32,
  },
});

